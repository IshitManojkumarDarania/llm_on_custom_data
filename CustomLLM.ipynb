{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKBuvV-Zqh05"
      },
      "outputs": [],
      "source": [
        "!pip install -U qdrant-client\n",
        "!pip install llama-index\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from llama_index import GPTVectorStoreIndex\n",
        "from llama_index import ServiceContext\n",
        "from llama_index import SimpleDirectoryReader\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = \"outputdirectory\""
      ],
      "metadata": {
        "id": "AUL1rfz-qykJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I have sent the api keys which were used by me in the mail these can also be created by visiting the websites of openai and qdrant\n",
        "os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_API\"\n",
        "os.environ['QDRANT_API_KEY'] = \"YOUR_QDRANT_API\"\n",
        "client = QdrantClient(\n",
        "    url=\"QDRANT_URL\",\n",
        "    api_key=\"QDRANT_API\",\n",
        ")\n",
        "service_context = ServiceContext.from_defaults()\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"BigBasket\")"
      ],
      "metadata": {
        "id": "Qy55Vdu_q42A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1a8137-374d-4bac-9a3f-1a0e8dbfa2a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE UPDATE THIS WITH YOUR LOCATION OF DATASET\n",
        "df=pd.read_csv(\"/content/bigBasketProducts.csv\")"
      ],
      "metadata": {
        "id": "dhzgVbWBsfII"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files(directory):\n",
        "    return list(os.scandir(directory))\n",
        "Path.ls = list_files\n",
        "files_dictionary = {row['product']: {column: row[column] for column in df.columns if column != 'product'} for _, row in df.iterrows()}\n",
        "if not os.path.exists(output_directory):\n",
        "    os.mkdir(output_directory)\n",
        "for key in files_dictionary.keys():\n",
        "    items = files_dictionary[key]\n",
        "    key_str = str(key)\n",
        "    file_path = f\"{output_directory}/\" + f\"{key_str.replace('/','*')}.txt\"\n",
        "    with open(file_path, \"w\") as myfile:\n",
        "        for item1, item2 in items.items():\n",
        "            myfile.write(f\"{item1}:{item2}\\n\")\n",
        "output_directory = Path(output_directory).resolve()"
      ],
      "metadata": {
        "id": "M7UqkCWotWCs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_metadata(file_name: str):\n",
        "    date_str = Path(file_name).stem.split(\"*\")[1:4]\n",
        "    return {\"product\": \":\".join(date_str)}\n",
        "products = SimpleDirectoryReader(file_metadata=generate_metadata, input_files=output_directory.ls()).load_data()"
      ],
      "metadata": {
        "id": "gf3EkAkct5Je"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#THIS WOULD TAKE A CONSIDERABLE TIME TO RUN PLEASE USE AN VALID OPEN AI API WHICH CAN PROCESS THIS MUCH DATA\n",
        "#IF IT TAKES TO LONG to see if it works you can use products = products[:50] to limit the number of entries from table that goes to model\n",
        "#it will always answer from that context only, ideally if you have the limit on your account we can remove products=products[:50] and the\n",
        "#answers will come from entire dataset\n",
        "products = products[:50]\n",
        "ranks = GPTVectorStoreIndex.from_documents(products, vector_store=vector_store, service_context=service_context)"
      ],
      "metadata": {
        "id": "anQFCecxuQ6V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ranks.as_query_engine()"
      ],
      "metadata": {
        "id": "-ebthJh4yFSz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLEASE ENTER YOUR QUERY HERE :\n",
        "response = model.query(\"what is the highest cost in snacks\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSZkUwAjyCVh",
        "outputId": "06acaa98-d0c2-466c-843f-7b9601b01729"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The highest cost in snacks is 70.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QXCnU7sVNpB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}